{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/ubuntu/')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from litellm import completion\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import nltk\n",
    "# nltk.download('words')\n",
    "from nltk.corpus import words\n",
    "import enchant\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from type import Trajectory, Word\n",
    "\n",
    "d = enchant.Dict(\"en_US\")\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "df = pd.read_csv('Wordle Words.csv')\n",
    "filtered_df = df.dropna().sort_values(by='occurrence', ascending=False)\n",
    "\n",
    "model_name = 'gpt-4o'\n",
    "custom_llm_provider='openai'\n",
    "api_base = \"https://api.openai.com/v1\"\n",
    "\n",
    "\n",
    "# model_name = 'hosted_vllm/Qwen2.5-7B-Instruct'\n",
    "# custom_llm_provider = 'vllm'\n",
    "# api_base = \"http://localhost:8000/v1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tells -> BGGGB\n"
     ]
    }
   ],
   "source": [
    "def get_feedback(word, guess, d):\n",
    "    \"\"\"\n",
    "    trajectory: list of tuples (word, result)\n",
    "    word: string\n",
    "    guess: string\n",
    "    \"\"\"\n",
    "    if not d.check(guess) and not guess in words.words():\n",
    "        return \"Invalid word, not a valid English word\"\n",
    "    \n",
    "    if len(guess) != 5:\n",
    "        return \"Invalid word, not a 5 letter word\"\n",
    "    \n",
    "    response = \"\"\n",
    "    response_text = \"\"\n",
    "    for i, alphabet in enumerate(guess):\n",
    "        if word[i] == alphabet:\n",
    "            response += \"G\"\n",
    "            response_text += f'{alphabet} is in the word and in the correct position.\\n'\n",
    "        elif alphabet in word:\n",
    "            response += \"Y\"\n",
    "            response_text += f'{alphabet} is in the word but in the wrong position.\\n'\n",
    "        else:\n",
    "            response += \"B\"\n",
    "            response_text += f'{alphabet} is not in the word.\\n'\n",
    "    return f\"{guess} -> {response}\"\n",
    "    # return f\"{guess} -> {response}\\n{response_text}\"\n",
    "\n",
    "print(get_feedback(\"hello\", \"tells\", d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a Wordle solver assistant. Your goal is to correctly guess the hidden 5-letter word within six attempts. The game provides feedback after each guess, which you must use to refine your subsequent guesses. Follow these rules and strategies carefully:\n",
    "\n",
    "== Wordle Rules ==\n",
    "1. The target word is exactly 5 letters long and is a valid English word.\n",
    "2. After each guess, you will receive feedback consisting of a string of 5 characters using the letters:\n",
    "   - G (Green): Correct letter in the correct position.\n",
    "   - Y (Yellow): Correct letter in the wrong position.\n",
    "   - B (Black): Letter is not in the target word at all.\n",
    "3. Use the feedback to eliminate invalid words and improve future guesses.\n",
    "\n",
    "== Feedback Interpretation Examples ==\n",
    "- Target word: \"hello\"\n",
    "- Guess: \"world\"\n",
    "- Feedback: \"BYBGB\"\n",
    "  Explanation:\n",
    "    - \"w\" → B: not in the target word\n",
    "    - \"o\" → Y: in the word, but not in position 2\n",
    "    - \"r\" → B: not in the word\n",
    "    - \"l\" → G: correct letter and position (index 3)\n",
    "    - \"d\" → B: not in the word\n",
    "\n",
    "== Your Responsibilities ==\n",
    "- Generate a single valid 5-letter English word for each turn.\n",
    "- Use previous guesses and their feedback to eliminate impossible candidates.\n",
    "- Prioritize guesses that test multiple hypotheses (e.g., new letters or positions) when unsure.\n",
    "- Think step-by-step to explain your reasoning before producing each guess.\n",
    "\n",
    "== Output Format ==\n",
    "Your response must follow this structure:\n",
    "<think>Explain your reasoning and deduction based on prior guesses and feedback.</think><answer>guess</answer>\n",
    "\n",
    "- The text inside <think> and </think> should include your full reasoning step by step. Do not ignore this step.\n",
    "- The word inside <answer> and </answer> must be your final guess.\n",
    "- The guess must be a single valid 5-letter English word in lowercase only.\n",
    "- Do not include any other text outside of the <think> and <answer> tags.\n",
    "\n",
    "== Goal ==\n",
    "Correctly identify the hidden word using logical deduction and strategic guessing, with clear and structured reasoning output.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def parser(text):\n",
    "    reasoning = re.search(r\"<think>(.*?)</think>\", text, re.DOTALL)\n",
    "    guess = re.search(r\"<answer>(.*?)</answer>\", text, re.DOTALL)\n",
    "    \n",
    "    if reasoning and guess:\n",
    "        return reasoning.group(1).strip(), guess.group(1).strip()\n",
    "    elif not reasoning and guess:\n",
    "        return None, guess.group(1).strip()\n",
    "    elif reasoning and not guess:\n",
    "        return reasoning.group(1).strip(), None\n",
    "    else:\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40325\n",
      "43032\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "def hash_word(s: str, bits=16):\n",
    "    hash_obj = hashlib.sha256(s.encode('utf-8'))\n",
    "    return int(hash_obj.hexdigest(), 16) % (2 ** bits)\n",
    "print(hash_word(\"wordle\"))\n",
    "print(hash_word(\"Wordle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sft_df = filtered_df.sample(500)\n",
    "words = []\n",
    "for idx, row in sft_df.iterrows():\n",
    "    df_index = idx\n",
    "    word = row['word']\n",
    "    occurrence = row['occurrence']\n",
    "    hash = hash_word(word)\n",
    "    W = Word(\n",
    "        df_index=df_index,\n",
    "        hash=hash,\n",
    "        word=word,\n",
    "        occurrence=occurrence,\n",
    "    )\n",
    "    words.append(W)\n",
    "\n",
    "def word_to_str(word: Word, indent: int = 4) -> str:\n",
    "    prefix = ' ' * indent\n",
    "    # Convert each field into a formatted key=value string\n",
    "    fields = [\n",
    "        f\"{k}={repr(v)}\" \n",
    "        for k, v in word.model_dump().items() \n",
    "        if v is not None\n",
    "    ]\n",
    "    return prefix + \"Word(\" + \", \".join(fields) + \")\"\n",
    "\n",
    "# Build the content list with indentation\n",
    "lines = [word_to_str(word, indent=4) for word in words]\n",
    "\n",
    "# Join into a full Python source file\n",
    "file_content = (\n",
    "    \"from type import Word\\n\\n\"\n",
    "    \"TRAIN_WORDS = [\\n\" +\n",
    "    \",\\n\".join(lines) +\n",
    "    \"\\n]\"\n",
    ")\n",
    "\n",
    "# Write the content to file\n",
    "with open(\"/home/ubuntu/Wordle/Data/train.py\", \"w\") as f:\n",
    "    f.write(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('WORDS: ', chosen_words)\n",
    "cost = 0.0\n",
    "\n",
    "total_games = 0\n",
    "games_won = 0\n",
    "\n",
    "\n",
    "for i, word in tqdm(enumerate(chosen_words)):\n",
    "    trajectory = [\n",
    "                {'role': 'system', 'content': system_prompt},\n",
    "                {'role': 'user', 'content': 'Your first guess is?'}\n",
    "                ]\n",
    "    print('New Word: ', word)\n",
    "    W = Word(\n",
    "        id=\n",
    "        word=word,\n",
    "    )\n",
    "    total_games += 1\n",
    "    \n",
    "    for j in range(6):\n",
    "        response = completion(model='o3', custom_llm_provider='openai', messages=trajectory)\n",
    "        # response = completion(model=model_name, api_base=api_base, messages=trajectory)\n",
    "        # Get the answer and reasoning, and add it to the trajectory\n",
    "        answer = response.choices[0].message.content\n",
    "        # Get the guess from the answer and get feedback\n",
    "        reasoning, guess = parser(answer)\n",
    "\n",
    "        if 'reasoning_content' in vars(response.choices[0].message):\n",
    "            reasoning = response.choices[0].message.reasoning_content\n",
    "            trajectory.append({'role': 'assistant', 'content': f'<think>{reasoning}</think><answer>{guess}</answer>'})\n",
    "        else:\n",
    "            trajectory.append({'role': 'assistant', 'content': answer})\n",
    "\n",
    "        if response._hidden_params[\"response_cost\"] is not None:\n",
    "            cost += response._hidden_params[\"response_cost\"]\n",
    "        \n",
    "        \n",
    "        feedback = None\n",
    "        if guess:\n",
    "            feedback = get_feedback(word, guess, d)\n",
    "            trajectory.append({'role': 'user', 'content': feedback})\n",
    "        else:\n",
    "            trajectory.append({'role': 'user', 'content': f'<think>Invalid format, stick to the <think>, </think> and <answer>, </answer> tags provided in the system prompt'})\n",
    "        \n",
    "        # If the feedback is 'GGGGG', break\n",
    "        print(f'{reasoning} {guess}')\n",
    "        if feedback.split('->')[-1].strip() == 'GGGGG':\n",
    "            print(f'Word {word} found in {j+1} turns')\n",
    "            games_won += 1\n",
    "            trajectory[-1]['content'] = f'Success! You found the word {word} in {j+1} turns.'\n",
    "            break\n",
    "\n",
    "    # print(trajectory)\n",
    "print('Total cost: ', cost)\n",
    "print('Total games: ', total_games)\n",
    "print('Games won: ', games_won)\n",
    "print('Win rate: ', games_won/total_games)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Write the word to words-used.json\n",
    "# Read existing data from words-used.json\n",
    "with open('Results/words-used.json', 'r') as f:\n",
    "    existing_words = json.load(f)\n",
    "\n",
    "# Append new word and write back\n",
    "existing_words.append(word)\n",
    "\n",
    "# Create the content with variable name\n",
    "content = f\"USED_WORDS = {json.dumps(existing_words, indent=2)}\"\n",
    "\n",
    "with open('Results/words-used.json', 'w') as f:\n",
    "    f.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read existing data from trajectories.json\n",
    "try:\n",
    "    with open('Results/trajectories.json', 'r') as f:\n",
    "        existing_trajectories = json.load(f)\n",
    "    if not isinstance(existing_trajectories, list):\n",
    "        existing_trajectories = [existing_trajectories]\n",
    "except (FileNotFoundError, json.JSONDecodeError):\n",
    "    existing_trajectories = []\n",
    "\n",
    "# Append new trajectory and write back\n",
    "existing_trajectories.append(trajectory)\n",
    "with open('Results/trajectories.json', 'w') as f:\n",
    "    json.dump(existing_trajectories, f, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded models:\n",
      "- ID: MERGED_WORDLE_UnslothFineTune_Qwen2.5-7B_Run3_16bit_r256_alpha256 | Owned by: vllm\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Replace with your vLLM server URL\n",
    "VLLM_SERVER_URL = \"http://localhost:8000\"\n",
    "\n",
    "def get_model_info():\n",
    "    try:\n",
    "        response = requests.get(f\"{VLLM_SERVER_URL}/v1/models\")\n",
    "        response.raise_for_status()\n",
    "        models = response.json().get(\"data\", [])\n",
    "        if not models:\n",
    "            print(\"No models are currently loaded.\")\n",
    "        else:\n",
    "            print(\"Loaded models:\")\n",
    "            for model in models:\n",
    "                print(f\"- ID: {model.get('id')} | Owned by: {model.get('owned_by', 'unknown')}\")\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error querying vLLM server: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_model_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Wordle.Data.train import TRAIN_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dicts = [word.model_dump() for word in TRAIN_WORDS]\n",
    "ds = Dataset.from_list(word_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type.Word() argument after ** must be a mapping, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m [Word(**item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m ds[\u001b[32m0\u001b[39m:\u001b[32m1\u001b[39m]]\n",
      "\u001b[31mTypeError\u001b[39m: type.Word() argument after ** must be a mapping, not str"
     ]
    }
   ],
   "source": [
    "[Word(**item) for item in ds[0:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word(df_index=5388, hash=20243, word='inlet', occurrence=6.439310127461795e-06, linked_trajectories=[], games_won=0, games_total=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word(**ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Word' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ds = \u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mWord\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mTRAIN_WORDS\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/datasets/arrow_dataset.py:985\u001b[39m, in \u001b[36mDataset.from_list\u001b[39m\u001b[34m(cls, mapping, features, info, split)\u001b[39m\n\u001b[32m    963\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    964\u001b[39m \u001b[33;03mConvert a list of dicts to a `pyarrow.Table` to create a [`Dataset`]`.\u001b[39;00m\n\u001b[32m    965\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    982\u001b[39m \u001b[33;03m    [`Dataset`]\u001b[39;00m\n\u001b[32m    983\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    984\u001b[39m \u001b[38;5;66;03m# for simplicity and consistency wrt OptimizedTypedSequence we do not use InMemoryTable.from_pylist here\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m985\u001b[39m mapping = {k: [\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(k) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m mapping] \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m mapping[\u001b[32m0\u001b[39m]} \u001b[38;5;28;01mif\u001b[39;00m mapping \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[32m    986\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.from_dict(mapping, features, info, split)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/pydantic/main.py:991\u001b[39m, in \u001b[36mBaseModel.__getattr__\u001b[39m\u001b[34m(self, item)\u001b[39m\n\u001b[32m    988\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__getattribute__\u001b[39m(item)  \u001b[38;5;66;03m# Raises AttributeError if appropriate\u001b[39;00m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    990\u001b[39m     \u001b[38;5;66;03m# this is the current error\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m991\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'Word' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_list([Word(**item.model_dump()) for item in TRAIN_WORDS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enchant.Dict"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'df_index': 12889,\n",
       " 'hash': 17684,\n",
       " 'word': 'zebra',\n",
       " 'occurrence': 6.835005632410685e-07,\n",
       " 'linked_trajectories': [],\n",
       " 'games_won': 0,\n",
       " 'games_total': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "content = json.load(open('/home/ubuntu/Wordle/Results/trajectories.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'zebra',\n",
       " 'word_hash': 17684,\n",
       " 'messages': [{'role': 'system',\n",
       "   'content': 'You are a Wordle solver assistant. Your goal is to correctly guess the hidden 5-letter word within six attempts. The game provides feedback after each guess, which you must use to refine your subsequent guesses. Follow these rules and strategies carefully:\\n\\n== Wordle Rules ==\\n1. The target word is exactly 5 letters long and is a valid English word.\\n2. After each guess, you will receive feedback consisting of a string of 5 characters using the letters:\\n   - G (Green): Correct letter in the correct position.\\n   - Y (Yellow): Correct letter in the wrong position.\\n   - B (Black): Letter is not in the target word at all.\\n3. Use the feedback to eliminate invalid words and improve future guesses.\\n\\n== Feedback Interpretation Examples ==\\n- Target word: \"hello\"\\n- Guess: \"world\"\\n- Feedback: \"BYBGB\"\\n  Explanation:\\n    - \"w\" → B: not in the target word\\n    - \"o\" → Y: in the word, but not in position 2\\n    - \"r\" → B: not in the word\\n    - \"l\" → G: correct letter and position (index 3)\\n    - \"d\" → B: not in the word\\n\\n== Your Responsibilities ==\\n- Generate a single valid 5-letter English word for each turn.\\n- Use previous guesses and their feedback to eliminate impossible candidates.\\n- Prioritize guesses that test multiple hypotheses (e.g., new letters or positions) when unsure.\\n- Think step-by-step to explain your reasoning before producing each guess.\\n\\n== Output Format ==\\nYour response must follow this structure:\\n<think>Explain your reasoning and deduction based on prior guesses and feedback.</think><answer>guess</answer>\\n\\n- The text inside <think> and </think> should include your full reasoning step by step. Do not ignore this step.\\n- The word inside <answer> and </answer> must be your final guess.\\n- The guess must be a single valid 5-letter English word in lowercase only.\\n- Do not include any other text outside of the <think> and <answer> tags.\\n\\n== Goal ==\\nCorrectly identify the hidden word using logical deduction and strategic guessing, with clear and structured reasoning output.'},\n",
       "  {'role': 'user', 'content': 'Your first guess is?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '<think>As the first move, I want a word that maximizes coverage of the most common consonants (s, t, l) and vowels (a, e). “slate” is a well-regarded opener that hits five high-frequency letters with no repeats, giving strong information for later filtering.</think><answer>slate</answer>'},\n",
       "  {'role': 'user', 'content': 'slate -> BBYBY'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '<think>Feedback from “slate” was BBYBY:\\n• s, l, t → B: these letters are not in the word anywhere  \\n• a → Y: “a” is in the word but NOT in position 3  \\n• e → Y: “e” is in the word but NOT in position 5  \\n\\nSo far we know:\\n• Letters present: a (≠pos3), e (≠pos5)  \\n• Letters absent: s, l, t  \\n• Remaining two slots are unknown letters; we should test new high-value consonants (c, n, r, h, m, p, etc.) and the vowel o.  \\n\\nCandidate must avoid s, l, t; place a somewhere other than index 3 and e somewhere other than index 5. “ocean” fits:  \\no (1)\\u2002c (2)\\u2002e (3)\\u2002a (4)\\u2002n (5)  \\n\\u2003– a is in pos4 (allowed)  \\n\\u2003– e is in pos3 (allowed)  \\n\\u2003– no forbidden letters.  \\nIt also introduces three new consonants (c, n, o) for strong information gain.</think><answer>ocean</answer>'},\n",
       "  {'role': 'user', 'content': 'ocean -> BBYYB'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '<think>Current knowledge  \\n1. slate → BBYBY  \\n\\u2003- a present, not pos3  \\n\\u2003- e present, not pos5  \\n\\u2003- s l t absent  \\n\\n2. ocean → BBYYB  \\n\\u2003- e present, not pos3  \\n\\u2003- a present, not pos4  \\n\\u2003- o c n absent  \\n\\nSummary of constraints  \\n• Present: a (¬3,4), e (¬3,5)  \\n• Absent: s l t o c n  \\n• Unknown two letters must be from the remaining alphabet.  \\n\\nPosition possibilities  \\n1: any except s l t o (a/e/other allowed)  \\n2: any except s l t c (a/e/other allowed)  \\n3: not a or e (and not absent letters)  \\n4: not a or t (e allowed)  \\n5: not e or n (a allowed)\\n\\nGoal for guess #3: keep both a and e in legal new positions and introduce three fresh consonants of high value (m, k, r).  \\nWord “maker” satisfies every rule:  \\nm (1) – new letter  \\na (2) – legal for a  \\nk (3) – new letter, avoids a/e  \\ne (4) – legal for e  \\nr (5) – new letter, avoids e/n  \\n\\nIt maximally broadens information while respecting all constraints.</think><answer>maker</answer>'},\n",
       "  {'role': 'user', 'content': 'maker -> BYBYY'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '<think>\\nWe have three pieces of feedback:\\n\\n1. slate → B B Y B Y  \\n   – a present, not pos3  \\n   – e present, not pos5  \\n   – s l t absent  \\n\\n2. ocean → B B Y Y B  \\n   – e present, not pos3  \\n   – a present, not pos4  \\n   – o c n absent  \\n\\n3. maker → B Y B Y Y  \\n   – a present, not pos2  \\n   – e present, not pos4  \\n   – r present, not pos5  \\n   – m k absent  \\n\\nConsolidated facts  \\n• Present letters: a (either pos1 or 5), e (pos1 or 2), r (pos1-4)  \\n• Absent letters: s l t o c n m k  \\n• Position bans:  \\n  – a ≠ 2,3,4  \\n  – e ≠ 3,4,5  \\n  – r ≠ 5  \\n\\nSo the structure must be:\\npos1/2 = e,  \\npos1/5 = a,  \\nr somewhere in pos1-4 (not 5).\\n\\nTry a = 5, e = 2 (fits all rules) → pattern _ e _ _ a with r in pos1/3/4.  \\nSearch the remaining word list (excluding forbidden letters). Viable dictionary words:\\n\\n• zebra  (z e b r a)  \\n• yerba  (y e r b a)  \\n• feria  (f e r i a)\\n\\n“zebra” stands out as the only common Wordle-answer-list word; the others are much less likely. It satisfies every constraint:\\n\\npos1 z (new, allowed)  \\npos2 e (allowed)  \\npos3 b (new, allowed)  \\npos4 r (allowed, r ≠ 5)  \\npos5 a (allowed, a ≠ 2-4)\\n\\nChoosing “zebra” tests two fresh consonants (z, b) while placing the mandatory a, e, r in legal slots. If it’s not correct, the feedback will almost certainly pinpoint the solution on the next turn.</think><answer>zebra</answer>'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Success! You found the word zebra in 4 turns.'}],\n",
       " 'completed_by': 'o3',\n",
       " 'completion_cost': 0.06806999999999999,\n",
       " 'solved': True}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "qualified_trajectories = [T for T in content if T['solved'] == True]\n",
    "train_trajectories, test_trajectories = train_test_split(qualified_trajectories, test_size=0.2, random_state=42)\n",
    "train_dataset = Dataset.from_list(train_trajectories)\n",
    "test_dataset = Dataset.from_list(test_trajectories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'word': 'inlet',\n",
       " 'word_hash': 20243,\n",
       " 'messages': [{'role': 'system',\n",
       "   'content': 'You are a Wordle solver assistant. Your goal is to correctly guess the hidden 5-letter word within six attempts. The game provides feedback after each guess, which you must use to refine your subsequent guesses. Follow these rules and strategies carefully:\\n\\n== Wordle Rules ==\\n1. The target word is exactly 5 letters long and is a valid English word.\\n2. After each guess, you will receive feedback consisting of a string of 5 characters using the letters:\\n   - G (Green): Correct letter in the correct position.\\n   - Y (Yellow): Correct letter in the wrong position.\\n   - B (Black): Letter is not in the target word at all.\\n3. Use the feedback to eliminate invalid words and improve future guesses.\\n\\n== Feedback Interpretation Examples ==\\n- Target word: \"hello\"\\n- Guess: \"world\"\\n- Feedback: \"BYBGB\"\\n  Explanation:\\n    - \"w\" → B: not in the target word\\n    - \"o\" → Y: in the word, but not in position 2\\n    - \"r\" → B: not in the word\\n    - \"l\" → G: correct letter and position (index 3)\\n    - \"d\" → B: not in the word\\n\\n== Your Responsibilities ==\\n- Generate a single valid 5-letter English word for each turn.\\n- Use previous guesses and their feedback to eliminate impossible candidates.\\n- Prioritize guesses that test multiple hypotheses (e.g., new letters or positions) when unsure.\\n- Think step-by-step to explain your reasoning before producing each guess.\\n\\n== Output Format ==\\nYour response must follow this structure:\\n<think>Explain your reasoning and deduction based on prior guesses and feedback.</think><answer>guess</answer>\\n\\n- The text inside <think> and </think> should include your full reasoning step by step. Do not ignore this step.\\n- The word inside <answer> and </answer> must be your final guess.\\n- The guess must be a single valid 5-letter English word in lowercase only.\\n- Do not include any other text outside of the <think> and <answer> tags.\\n\\n== Goal ==\\nCorrectly identify the hidden word using logical deduction and strategic guessing, with clear and structured reasoning output.'},\n",
       "  {'role': 'user', 'content': 'Your first guess is?'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '<think>We have no feedback yet, so the optimal first move is to choose a word that contains five highly frequent English letters, giving us maximum information about both vowels and common consonants. “slate” is a widely used opener because it tests three common consonants (s, l, t) and two common vowels (a, e). This balances coverage and positional information well.</think><answer>slate</answer>'},\n",
       "  {'role': 'user', 'content': 'slate -> BYBYY'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '<think>Feedback from “slate” (BYBYY):\\n\\nPosition 1: s → B ⇒ ‘s’ is absent from the target.\\nPosition 2: l → Y ⇒ ‘l’ is in the word but NOT in position 2.\\nPosition 3: a → B ⇒ ‘a’ is absent.\\nPosition 4: t → Y ⇒ ‘t’ is in the word but NOT in position 4.\\nPosition 5: e → Y ⇒ ‘e’ is in the word but NOT in position 5.\\n\\nCurrent constraints:\\n• Required letters somewhere: l (≠2), t (≠4), e (≠5)  \\n• Forbidden letters: s, a  \\n• All other letters still unknown.\\n\\nGoal for guess 2: place l, t, e in allowed positions while introducing two new consonants/vowels for more coverage.\\n\\nCandidate word “towel” (t o w e l):\\n– Uses l in position 5 (allowed), t in position 1 (allowed), e in position 4 (allowed).\\n– Introduces two fresh letters ‘o’ and ‘w’.\\n– Respects all constraints (no s or a, l not in pos 2, t not in pos 4, e not in pos 5).\\n\\nTherefore “towel” is a strong exploratory guess.</think><answer>towel</answer>'},\n",
       "  {'role': 'user', 'content': 'towel -> YBBGY'},\n",
       "  {'role': 'assistant',\n",
       "   'content': '<think>We interpret “towel → Y B B G Y” as follows:\\n\\n• Position 1: t got Y ⇒ ‘t’ is in the word but **not** in position 1.  \\n• Position 2: o got B ⇒ ‘o’ is absent.  \\n• Position 3: w got B ⇒ ‘w’ is absent.  \\n• Position 4: e got G ⇒ ‘e’ is fixed in position 4.  \\n• Position 5: l got Y ⇒ ‘l’ is present but **not** in position 5.\\n\\nCombine with the first-guess information:\\n\\n– ‘s’ and ‘a’ are also absent.  \\n– ‘l’ is present, but not in positions 2 or 5 (so only 1 or 3 remain).  \\n– ‘t’ is present, but not in positions 1 or 4 (so 2, 3, 5 remain).  \\n– Letters banned so far: s, a, o, w.  \\n– Word pattern: _ _ _ e _ with mandatory letters l (pos 1/3) and t (pos 2/3/5).\\n\\nWe now look for valid English words that:\\n\\n1. Have e in position 4.  \\n2. Place l in position 1 or 3 (not 2,5).  \\n3. Place t in position 2, 3, or 5 (not 1,4).  \\n4. Avoid s, a, o, w.  \\n5. Preferably introduce new letters to gather information.\\n\\nA strong candidate is “inlet”:\\n\\n• i n l e t  \\n  – e is correctly at position 4.  \\n  – l is at position 3 (allowed).  \\n  – t is at position 5 (allowed).  \\n  – Introduces two fresh letters, i and n, thus maximizing information.  \\n  – No forbidden letters are used.  \\n\\nOther possibles like “filet” also fit, but “inlet” uses higher-frequency letters (i, n) and keeps maximal exploratory value.\\n\\nHence “inlet” is our third guess.</think><answer>inlet</answer>'},\n",
       "  {'role': 'user',\n",
       "   'content': 'Success! You found the word inlet in 3 turns.'}],\n",
       " 'completed_by': 'o3',\n",
       " 'completion_cost': 0.037675999999999994,\n",
       " 'solved': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported, apply_chat_template\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, DataCollatorForSeq2Seq\n",
    "from typing import Optional\n",
    "import torch\n",
    "\n",
    "def load_data(dataset_path = '/home/ubuntu/Wordle/Results/trajectories.json'):\n",
    "    content = json.load(open(dataset_path))\n",
    "    qualified_trajectories = [T for T in content if T['solved'] == True]\n",
    "    train_trajectories, test_trajectories = train_test_split(qualified_trajectories, test_size=0.2, random_state=42)\n",
    "    train_dataset = Dataset.from_list(train_trajectories)\n",
    "    test_dataset = Dataset.from_list(test_trajectories)\n",
    "    return train_dataset, test_dataset\n",
    "\n",
    "def load_model_and_tokenizer(\n",
    "    model_name: str = \"Qwen/Qwen2.5-7B-Instruct\",\n",
    "    max_seq_length: int = 20000,\n",
    "    dtype: Optional[torch.dtype] = None,\n",
    "    load_in_4bit: bool = True,\n",
    "    load_in_8bit: bool = False,\n",
    "    r: int = 16,\n",
    "    lora_alpha: int = 32,\n",
    ") -> tuple[AutoModelForCausalLM, AutoTokenizer]:\n",
    "    \"\"\"\n",
    "    Load a model and tokenizer with specified configurations.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name or path of the model to load\n",
    "        max_seq_length: Maximum sequence length for the model\n",
    "        dtype: Data type for model weights\n",
    "        load_in_4bit: Whether to load the model in 4-bit quantization\n",
    "        load_in_8bit: Whether to load the model in 8-bit quantization\n",
    "    Returns:\n",
    "        Tuple containing the loaded model and tokenizer\n",
    "    \"\"\"\n",
    "\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name=model_name,\n",
    "        max_seq_length=max_seq_length,\n",
    "        dtype=dtype,\n",
    "        load_in_4bit=load_in_4bit,\n",
    "        load_in_8bit=load_in_8bit\n",
    "    )\n",
    "\n",
    "    model = FastLanguageModel.get_peft_model(\n",
    "            model,\n",
    "            r = r, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "            target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                            \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "            lora_alpha = lora_alpha,\n",
    "            lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "            bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "            # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "            use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "            random_state = 3407,\n",
    "            use_rslora = False,  # We support rank stabilized LoRA\n",
    "            loftq_config = None, # And LoftQ\n",
    "            )\n",
    "    \n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model with r=16 and lora_alpha=32\n",
      "==((====))==  Unsloth 2025.6.5: Fast Qwen2 patching. Transformers: 4.52.4. vLLM: 0.9.1.\n",
      "   \\\\   /|    NVIDIA A10G. Num GPUs = 1. Max memory: 22.184 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 8.6. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b23aed0650bd45ae946aff0e584fec22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.6.5 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "project_name = 'Wordle-Qwen2.5-7B'\n",
    "run_name = 'UnslothFineTune_Qwen2.5-7B_Run1_4bit'\n",
    "\n",
    "train_dataset, test_dataset = load_data()\n",
    "\n",
    "model_name = \"/home/ubuntu/TauBench/tau-bench/Model Tuning/Qwen2.5-7B-Instruct\"\n",
    "load_in_8bit = False\n",
    "load_in_4bit = True\n",
    "dtype=torch.bfloat16 if is_bfloat16_supported() else torch.float16\n",
    "max_seq_length = 20000\n",
    "r = 16\n",
    "lora_alpha = 32\n",
    "print(f\"Loading model with r={r} and lora_alpha={lora_alpha}\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "\n",
    "model, tokenizer = load_model_and_tokenizer(\n",
    "                                            model_name= model_name,\n",
    "                                            max_seq_length= max_seq_length,\n",
    "                                            dtype=dtype,\n",
    "                                            load_in_4bit=load_in_4bit,\n",
    "                                            load_in_8bit=load_in_8bit,\n",
    "                                            r=r,\n",
    "                                            lora_alpha=lora_alpha)\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_target(target, seq):\n",
    "    for i in range(len(seq) - len(target) + 1):\n",
    "        if seq[i:i + len(target)] == target:\n",
    "            seq[i:i + len(target)] = [-100] * len(target)\n",
    "    return seq\n",
    "\n",
    "def tokenize_dialog(dialog, tokenizer, EOS_TOKEN, max_seq_length):\n",
    "    \"\"\"\n",
    "    Tokenizes a full dialog using Qwen's chat template, and masks non-assistant tokens.\n",
    "    \"\"\"\n",
    "    # 1. Render the full conversation using the chat template\n",
    "    EOT_ID = tokenizer.encode(EOS_TOKEN, add_special_tokens=False)[0]\n",
    "    rendered_text = tokenizer.apply_chat_template(dialog, tokenize=False, add_generation_prompt=False)\n",
    "\n",
    "    # 2. Tokenize that text (this returns a dict with 'input_ids', etc.)\n",
    "    tokenized = tokenizer(rendered_text, return_tensors=None, add_special_tokens=False)\n",
    "    \n",
    "    # Cuda OOM issues, so we truncate the text all the way down to 128 tokens\n",
    "    # tokenized = tokenizer(rendered_text, return_tensors=None, add_special_tokens=False, truncation=True, max_length=max_seq_length)\n",
    "    \n",
    "    input_ids = tokenized[\"input_ids\"]\n",
    "\n",
    "    # 3. Copy for label masking\n",
    "    labels = copy.deepcopy(input_ids)\n",
    "\n",
    "    # 4. Find indices of <|eot_id|> tokens (EOT)\n",
    "    eot_indices = [i for i, token in enumerate(input_ids) if token == EOT_ID]\n",
    "\n",
    "    # 5. Get role tokens\n",
    "    system_token = tokenizer.encode(\"system\", add_special_tokens=False)[-1]\n",
    "    user_token = tokenizer.encode(\"user\", add_special_tokens=False)[-1]\n",
    "\n",
    "    labels[0] = -100  # Mask BOS or first token\n",
    "\n",
    "    last_idx = None\n",
    "    for idx in eot_indices:\n",
    "        if last_idx is None:\n",
    "            role_token = input_ids[1]\n",
    "            last_idx = -1\n",
    "        else:\n",
    "            role_token = input_ids[last_idx+3] if last_idx+3 < len(input_ids) else None\n",
    "        if role_token in (system_token, user_token):\n",
    "            labels[last_idx + 1: idx + 2] = [-100] * (idx + 2 - last_idx -1)\n",
    "        last_idx = idx\n",
    "    \n",
    "    # 6. Mask assistant headers\n",
    "    assistant_header = tokenizer.encode(\"<|im_start|>assistant\\n\", add_special_tokens=False)\n",
    "    labels = mask_target(assistant_header, labels)\n",
    "\n",
    "    return {\n",
    "        \"input_ids\": torch.tensor(input_ids, device='cuda'),\n",
    "        \"labels\": torch.tensor(labels, device='cuda'),\n",
    "        \"attention_mask\": torch.tensor([1] * len(input_ids), device='cuda'),\n",
    "        \"text\": rendered_text\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2409\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in range(len(train_dataset)):\n",
    "    processed = tokenize_dialog(train_dataset[i]['messages'], tokenizer, EOS_TOKEN, max_seq_length)\n",
    "    if len(processed['input_ids']) > max_len:\n",
    "        max_len = len(processed['labels'])\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a Wordle solver assistant. Your goal is to correctly guess the hidden 5-letter word within six attempts. The game provides feedback after each guess, which you must use to refine your subsequent guesses. Follow these rules and strategies carefully:\\n\\n== Wordle Rules ==\\n1. The target word is exactly 5 letters long and is a valid English word.\\n2. After each guess, you will receive feedback consisting of a string of 5 characters using the letters:\\n   - G (Green): Correct letter in the correct position.\\n   - Y (Yellow): Correct letter in the wrong position.\\n   - B (Black): Letter is not in the target word at all.\\n3. Use the feedback to eliminate invalid words and improve future guesses.\\n\\n== Feedback Interpretation Examples ==\\n- Target word: \"hello\"\\n- Guess: \"world\"\\n- Feedback: \"BYBGB\"\\n  Explanation:\\n    - \"w\" → B: not in the target word\\n    - \"o\" → Y: in the word, but not in position 2\\n    - \"r\" → B: not in the word\\n    - \"l\" → G: correct letter and position (index 3)\\n    - \"d\" → B: not in the word\\n\\n== Your Responsibilities ==\\n- Generate a single valid 5-letter English word for each turn.\\n- Use previous guesses and their feedback to eliminate impossible candidates.\\n- Prioritize guesses that test multiple hypotheses (e.g., new letters or positions) when unsure.\\n- Think step-by-step to explain your reasoning before producing each guess.\\n\\n== Output Format ==\\nYour response must follow this structure:\\n<think>Explain your reasoning and deduction based on prior guesses and feedback.</think><answer>guess</answer>\\n\\n- The text inside <think> and </think> should include your full reasoning step by step. Do not ignore this step.\\n- The word inside <answer> and </answer> must be your final guess.\\n- The guess must be a single valid 5-letter English word in lowercase only.\\n- Do not include any other text outside of the <think> and <answer> tags.\\n\\n== Goal ==\\nCorrectly identify the hidden word using logical deduction and strategic guessing, with clear and structured reasoning output.<|im_end|>\\n<|im_start|>user\\nYour first guess is?<|im_end|>\\n<|im_start|>assistant\\n<think>For the opening move, I want a word containing several of the most common consonants (s, t, l) and vowels (a, e) to maximize information. “slate” is a well-balanced starter that tests five high-frequency letters and provides good coverage for both vowels and consonants.</think><answer>slate</answer><|im_end|>\\n<|im_start|>user\\nslate -> BYYBB<|im_end|>\\n<|im_start|>assistant\\n<think>Feedback “BYYBB” from “slate” means:\\n• s (pos1) – B → s is not in the word.  \\n• l (pos2) – Y → l is in the word but NOT in position 2.  \\n• a (pos3) – Y → a is in the word but NOT in position 3.  \\n• t (pos4) – B → t is not in the word.  \\n• e (pos5) – B → e is not in the word.  \\n\\nCurrent constraints  \\n– Contains: l (≠ pos2), a (≠ pos3)  \\n– Excludes: s, t, e  \\n– Positions 4 and 5 completely open; positions 1 and 3 cannot be l and a respectively, but could hold other letters.  \\n– Still need to learn about other common letters (o, u, i, n, r, d, c, h, p, etc.).\\n\\nI want a word that:  \\n1. Places l and a in allowable positions, satisfying their Y clues,  \\n2. Introduces three new high-value letters to maximise information, and  \\n3. Avoids the banned letters s, t, e.\\n\\n“lunar” fits:  \\n– l in position 1 (allowed)  \\n– u n r are fresh letters to test  \\n– a in position 4 (allowed, not position 3)  \\n– No s/t/e.\\n\\nThis guess advances knowledge on two more vowels (u) and several frequent consonants (n, r) while honoring all constraints.</think><answer>lunar</answer><|im_end|>\\n<|im_start|>user\\nlunar -> YBBGY<|im_end|>\\n<|im_start|>assistant\\n<think>From the two guesses so far we have these firm constraints:\\n\\n• a is Green in position 4  → pattern _ _ _ a _  \\n• l is in the word but NOT in positions 1 or 2  \\n• r is in the word but NOT in position 5  \\n• Letters that are definitely absent: s, t, e, u, n  \\n  (from “slate” and “lunar”)  \\n\\nOpen slots: positions 1, 2, 3, 5.  \\nWe still need at least the letters l and r placed somewhere among those slots, with l ≠1,2 and r ≠5.  \\n\\nI’d like a candidate that  \\n1. Puts l and r in legal positions,  \\n2. Tries a high-value new vowel (o) and another common consonant,  \\n3. Respects all exclusions.  \\n\\nA strong option is “coral”:  \\n• c o r a l  \\n  – a is fixed at position 4 (good)  \\n  – r goes to position 3 (allowed, not 5)  \\n  – l goes to position 5 (allowed, not 1/2)  \\n  – introduces two fresh letters, c and o, while testing the very frequent vowel o.\\n\\nIf “coral” is wrong it will still give plenty of information about where r and l belong and about the presence of o and c. It satisfies every known constraint, so it’s a solid third-round probe.</think><answer>coral</answer><|im_end|>\\n<|im_start|>user\\ncoral -> BGYGG<|im_end|>\\n<|im_start|>assistant\\n<think>\\nFrom “coral” → B G Y G G we have:\\n• c (pos1) B → c absent.  \\n• o (pos2) G → o is fixed at position 2.  \\n• r (pos3) Y → r is in the word but not at position 3.  \\n• a (pos4) G → a is fixed at position 4.  \\n• l (pos5) G → l is fixed at position 5.  \\n\\nEarlier clues still apply:  \\n– l was Y in position 1 of “lunar”, so l could not be position 1 or 2; position 5 is now confirmed green, consistent.  \\n– r was Y in position 5 of “lunar”, so r cannot be position 5. Now we also know r cannot be position 3.  \\nTherefore the only remaining open slot for r is position 1.\\n\\nCurrent pattern:  r o _ a l\\nRemaining unknown letter is position 3.  \\nExcluded letters so far: s, t, e, u, n, c.  \\nAllowed unused letters include y, p, d, g, h, m, i, b, f, k, q, v, w, x, z.\\n\\nLooking for a common English word of form “ro ? al” with the exclusions:\\n• royal (r o y a l) fits perfectly—uses a new letter y, obeys all constraints, and looks like the only ordinary English word that matches.\\n\\nThus “royal” is the logical next guess.</think><answer>royal</answer><|im_end|>\\n<|im_start|>user\\nSuccess! You found the word royal in 4 turns.<|im_end|>\\n'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "tensor(13708, device='cuda:0') <th\n",
      "tensor(766, device='cuda:0') ink\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(2461, device='cuda:0') For\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(8568, device='cuda:0')  opening\n",
      "tensor(3271, device='cuda:0')  move\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(358, device='cuda:0')  I\n",
      "tensor(1366, device='cuda:0')  want\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(8482, device='cuda:0')  containing\n",
      "tensor(3807, device='cuda:0')  several\n",
      "tensor(315, device='cuda:0')  of\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(1429, device='cuda:0')  most\n",
      "tensor(4185, device='cuda:0')  common\n",
      "tensor(77505, device='cuda:0')  conson\n",
      "tensor(1783, device='cuda:0') ants\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(82, device='cuda:0') s\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(259, device='cuda:0')  t\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(78456, device='cuda:0')  vowels\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(64, device='cuda:0') a\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(384, device='cuda:0')  e\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(311, device='cuda:0')  to\n",
      "tensor(34508, device='cuda:0')  maximize\n",
      "tensor(1995, device='cuda:0')  information\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(3226, device='cuda:0') sl\n",
      "tensor(349, device='cuda:0') ate\n",
      "tensor(854, device='cuda:0') ”\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(1632, device='cuda:0')  well\n",
      "tensor(83125, device='cuda:0') -bal\n",
      "tensor(4874, device='cuda:0') anced\n",
      "tensor(26697, device='cuda:0')  starter\n",
      "tensor(429, device='cuda:0')  that\n",
      "tensor(7032, device='cuda:0')  tests\n",
      "tensor(4236, device='cuda:0')  five\n",
      "tensor(1550, device='cuda:0')  high\n",
      "tensor(78312, device='cuda:0') -frequency\n",
      "tensor(11931, device='cuda:0')  letters\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(5707, device='cuda:0')  provides\n",
      "tensor(1661, device='cuda:0')  good\n",
      "tensor(10191, device='cuda:0')  coverage\n",
      "tensor(369, device='cuda:0')  for\n",
      "tensor(2176, device='cuda:0')  both\n",
      "tensor(78456, device='cuda:0')  vowels\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(77505, device='cuda:0')  conson\n",
      "tensor(1783, device='cuda:0') ants\n",
      "tensor(3918, device='cuda:0') .</\n",
      "tensor(26865, device='cuda:0') think\n",
      "tensor(1784, device='cuda:0') ><\n",
      "tensor(9217, device='cuda:0') answer\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(3226, device='cuda:0') sl\n",
      "tensor(349, device='cuda:0') ate\n",
      "tensor(522, device='cuda:0') </\n",
      "tensor(9217, device='cuda:0') answer\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(151645, device='cuda:0') <|im_end|>\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "tensor(13708, device='cuda:0') <th\n",
      "tensor(766, device='cuda:0') ink\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(35348, device='cuda:0') Feedback\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(33, device='cuda:0') B\n",
      "tensor(10060, device='cuda:0') YY\n",
      "tensor(10098, device='cuda:0') BB\n",
      "tensor(854, device='cuda:0') ”\n",
      "tensor(504, device='cuda:0')  from\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(3226, device='cuda:0') sl\n",
      "tensor(349, device='cuda:0') ate\n",
      "tensor(854, device='cuda:0') ”\n",
      "tensor(3363, device='cuda:0')  means\n",
      "tensor(510, device='cuda:0') :\n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(274, device='cuda:0')  s\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(966, device='cuda:0') pos\n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(1365, device='cuda:0')  –\n",
      "tensor(425, device='cuda:0')  B\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(274, device='cuda:0')  s\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(537, device='cuda:0')  not\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(966, device='cuda:0') pos\n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(1365, device='cuda:0')  –\n",
      "tensor(809, device='cuda:0')  Y\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(714, device='cuda:0')  but\n",
      "tensor(4183, device='cuda:0')  NOT\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(966, device='cuda:0') pos\n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(1365, device='cuda:0')  –\n",
      "tensor(809, device='cuda:0')  Y\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(714, device='cuda:0')  but\n",
      "tensor(4183, device='cuda:0')  NOT\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(259, device='cuda:0')  t\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(966, device='cuda:0') pos\n",
      "tensor(19, device='cuda:0') 4\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(1365, device='cuda:0')  –\n",
      "tensor(425, device='cuda:0')  B\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(259, device='cuda:0')  t\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(537, device='cuda:0')  not\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(384, device='cuda:0')  e\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(966, device='cuda:0') pos\n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(1365, device='cuda:0')  –\n",
      "tensor(425, device='cuda:0')  B\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(384, device='cuda:0')  e\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(537, device='cuda:0')  not\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(18611, device='cuda:0')   \n",
      "\n",
      "\n",
      "tensor(5405, device='cuda:0') Current\n",
      "tensor(16982, device='cuda:0')  constraints\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(4142, device='cuda:0') –\n",
      "tensor(30811, device='cuda:0')  Contains\n",
      "tensor(25, device='cuda:0') :\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(145129, device='cuda:0') ≠\n",
      "tensor(1133, device='cuda:0')  pos\n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(701, device='cuda:0') ),\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(145129, device='cuda:0') ≠\n",
      "tensor(1133, device='cuda:0')  pos\n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(4142, device='cuda:0') –\n",
      "tensor(1374, device='cuda:0')  Ex\n",
      "tensor(7396, device='cuda:0') cludes\n",
      "tensor(25, device='cuda:0') :\n",
      "tensor(274, device='cuda:0')  s\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(259, device='cuda:0')  t\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(384, device='cuda:0')  e\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(4142, device='cuda:0') –\n",
      "tensor(75383, device='cuda:0')  Positions\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(19, device='cuda:0') 4\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(6587, device='cuda:0')  completely\n",
      "tensor(1787, device='cuda:0')  open\n",
      "tensor(26, device='cuda:0') ;\n",
      "tensor(9892, device='cuda:0')  positions\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(4157, device='cuda:0')  cannot\n",
      "tensor(387, device='cuda:0')  be\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(15576, device='cuda:0')  respectively\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(714, device='cuda:0')  but\n",
      "tensor(1410, device='cuda:0')  could\n",
      "tensor(3331, device='cuda:0')  hold\n",
      "tensor(1008, device='cuda:0')  other\n",
      "tensor(11931, device='cuda:0')  letters\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(4142, device='cuda:0') –\n",
      "tensor(16377, device='cuda:0')  Still\n",
      "tensor(1184, device='cuda:0')  need\n",
      "tensor(311, device='cuda:0')  to\n",
      "tensor(3960, device='cuda:0')  learn\n",
      "tensor(911, device='cuda:0')  about\n",
      "tensor(1008, device='cuda:0')  other\n",
      "tensor(4185, device='cuda:0')  common\n",
      "tensor(11931, device='cuda:0')  letters\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(78, device='cuda:0') o\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(575, device='cuda:0')  u\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(600, device='cuda:0')  i\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(308, device='cuda:0')  n\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(294, device='cuda:0')  d\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(272, device='cuda:0')  c\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(305, device='cuda:0')  h\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(281, device='cuda:0')  p\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(4992, device='cuda:0')  etc\n",
      "tensor(74203, device='cuda:0') .).\n",
      "\n",
      "\n",
      "tensor(40, device='cuda:0') I\n",
      "tensor(1366, device='cuda:0')  want\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(429, device='cuda:0')  that\n",
      "tensor(25, device='cuda:0') :\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(44736, device='cuda:0')  Places\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(84752, device='cuda:0')  allowable\n",
      "tensor(9892, device='cuda:0')  positions\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(36054, device='cuda:0')  satisfying\n",
      "tensor(862, device='cuda:0')  their\n",
      "tensor(809, device='cuda:0')  Y\n",
      "tensor(42675, device='cuda:0')  clues\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(1333, device='cuda:0')  Int\n",
      "tensor(4550, device='cuda:0') rodu\n",
      "tensor(1603, device='cuda:0') ces\n",
      "tensor(2326, device='cuda:0')  three\n",
      "tensor(501, device='cuda:0')  new\n",
      "tensor(1550, device='cuda:0')  high\n",
      "tensor(19083, device='cuda:0') -value\n",
      "tensor(11931, device='cuda:0')  letters\n",
      "tensor(311, device='cuda:0')  to\n",
      "tensor(30027, device='cuda:0')  maxim\n",
      "tensor(1064, device='cuda:0') ise\n",
      "tensor(1995, device='cuda:0')  information\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(34006, device='cuda:0')  Avoid\n",
      "tensor(82, device='cuda:0') s\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(20834, device='cuda:0')  banned\n",
      "tensor(11931, device='cuda:0')  letters\n",
      "tensor(274, device='cuda:0')  s\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(259, device='cuda:0')  t\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(384, device='cuda:0')  e\n",
      "tensor(382, device='cuda:0') .\n",
      "\n",
      "\n",
      "tensor(2073, device='cuda:0') “\n",
      "tensor(75, device='cuda:0') l\n",
      "tensor(84992, device='cuda:0') unar\n",
      "tensor(854, device='cuda:0') ”\n",
      "tensor(18304, device='cuda:0')  fits\n",
      "tensor(25, device='cuda:0') :\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(4142, device='cuda:0') –\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(20967, device='cuda:0') allowed\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(4142, device='cuda:0') –\n",
      "tensor(575, device='cuda:0')  u\n",
      "tensor(308, device='cuda:0')  n\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(525, device='cuda:0')  are\n",
      "tensor(7722, device='cuda:0')  fresh\n",
      "tensor(11931, device='cuda:0')  letters\n",
      "tensor(311, device='cuda:0')  to\n",
      "tensor(1273, device='cuda:0')  test\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(4142, device='cuda:0') –\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(19, device='cuda:0') 4\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(20967, device='cuda:0') allowed\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(537, device='cuda:0')  not\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(4142, device='cuda:0') –\n",
      "tensor(2308, device='cuda:0')  No\n",
      "tensor(274, device='cuda:0')  s\n",
      "tensor(5523, device='cuda:0') /t\n",
      "tensor(16546, device='cuda:0') /e\n",
      "tensor(382, device='cuda:0') .\n",
      "\n",
      "\n",
      "tensor(1986, device='cuda:0') This\n",
      "tensor(7942, device='cuda:0')  guess\n",
      "tensor(29903, device='cuda:0')  advances\n",
      "tensor(6540, device='cuda:0')  knowledge\n",
      "tensor(389, device='cuda:0')  on\n",
      "tensor(1378, device='cuda:0')  two\n",
      "tensor(803, device='cuda:0')  more\n",
      "tensor(78456, device='cuda:0')  vowels\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(84, device='cuda:0') u\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(3807, device='cuda:0')  several\n",
      "tensor(20757, device='cuda:0')  frequent\n",
      "tensor(77505, device='cuda:0')  conson\n",
      "tensor(1783, device='cuda:0') ants\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(77, device='cuda:0') n\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(1393, device='cuda:0')  while\n",
      "tensor(77925, device='cuda:0')  honoring\n",
      "tensor(678, device='cuda:0')  all\n",
      "tensor(16982, device='cuda:0')  constraints\n",
      "tensor(3918, device='cuda:0') .</\n",
      "tensor(26865, device='cuda:0') think\n",
      "tensor(1784, device='cuda:0') ><\n",
      "tensor(9217, device='cuda:0') answer\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(75, device='cuda:0') l\n",
      "tensor(84992, device='cuda:0') unar\n",
      "tensor(522, device='cuda:0') </\n",
      "tensor(9217, device='cuda:0') answer\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(151645, device='cuda:0') <|im_end|>\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "tensor(13708, device='cuda:0') <th\n",
      "tensor(766, device='cuda:0') ink\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(3830, device='cuda:0') From\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(1378, device='cuda:0')  two\n",
      "tensor(60537, device='cuda:0')  guesses\n",
      "tensor(773, device='cuda:0')  so\n",
      "tensor(3041, device='cuda:0')  far\n",
      "tensor(582, device='cuda:0')  we\n",
      "tensor(614, device='cuda:0')  have\n",
      "tensor(1493, device='cuda:0')  these\n",
      "tensor(7474, device='cuda:0')  firm\n",
      "tensor(16982, device='cuda:0')  constraints\n",
      "tensor(1447, device='cuda:0') :\n",
      "\n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(7840, device='cuda:0')  Green\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(19, device='cuda:0') 4\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(5383, device='cuda:0')  pattern\n",
      "tensor(716, device='cuda:0')  _\n",
      "tensor(716, device='cuda:0')  _\n",
      "tensor(716, device='cuda:0')  _\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(716, device='cuda:0')  _\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(714, device='cuda:0')  but\n",
      "tensor(4183, device='cuda:0')  NOT\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(9892, device='cuda:0')  positions\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(476, device='cuda:0')  or\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(714, device='cuda:0')  but\n",
      "tensor(4183, device='cuda:0')  NOT\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(44297, device='cuda:0')  Letters\n",
      "tensor(429, device='cuda:0')  that\n",
      "tensor(525, device='cuda:0')  are\n",
      "tensor(8491, device='cuda:0')  definitely\n",
      "tensor(27211, device='cuda:0')  absent\n",
      "tensor(25, device='cuda:0') :\n",
      "tensor(274, device='cuda:0')  s\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(259, device='cuda:0')  t\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(384, device='cuda:0')  e\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(575, device='cuda:0')  u\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(308, device='cuda:0')  n\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(1499, device='cuda:0') from\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(3226, device='cuda:0') sl\n",
      "tensor(349, device='cuda:0') ate\n",
      "tensor(854, device='cuda:0') ”\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(75, device='cuda:0') l\n",
      "tensor(84992, device='cuda:0') unar\n",
      "tensor(32511, device='cuda:0') ”)\n",
      "tensor(18611, device='cuda:0')   \n",
      "\n",
      "\n",
      "tensor(5002, device='cuda:0') Open\n",
      "tensor(15711, device='cuda:0')  slots\n",
      "tensor(25, device='cuda:0') :\n",
      "tensor(9892, device='cuda:0')  positions\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(1654, device='cuda:0') We\n",
      "tensor(2058, device='cuda:0')  still\n",
      "tensor(1184, device='cuda:0')  need\n",
      "tensor(518, device='cuda:0')  at\n",
      "tensor(3245, device='cuda:0')  least\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(11931, device='cuda:0')  letters\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(9099, device='cuda:0')  placed\n",
      "tensor(14696, device='cuda:0')  somewhere\n",
      "tensor(4221, device='cuda:0')  among\n",
      "tensor(1846, device='cuda:0')  those\n",
      "tensor(15711, device='cuda:0')  slots\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(448, device='cuda:0')  with\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(94304, device='cuda:0')  ≠\n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(94304, device='cuda:0')  ≠\n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(18611, device='cuda:0')   \n",
      "\n",
      "\n",
      "tensor(40, device='cuda:0') I\n",
      "tensor(6925, device='cuda:0') ’d\n",
      "tensor(1075, device='cuda:0')  like\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(9144, device='cuda:0')  candidate\n",
      "tensor(429, device='cuda:0')  that\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(393, device='cuda:0')  P\n",
      "tensor(6128, device='cuda:0') uts\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(5777, device='cuda:0')  legal\n",
      "tensor(9892, device='cuda:0')  positions\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(350, device='cuda:0')  T\n",
      "tensor(4019, device='cuda:0') ries\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(1550, device='cuda:0')  high\n",
      "tensor(19083, device='cuda:0') -value\n",
      "tensor(501, device='cuda:0')  new\n",
      "tensor(76181, device='cuda:0')  vowel\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(78, device='cuda:0') o\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(2441, device='cuda:0')  another\n",
      "tensor(4185, device='cuda:0')  common\n",
      "tensor(77505, device='cuda:0')  conson\n",
      "tensor(517, device='cuda:0') ant\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(1800, device='cuda:0')  Res\n",
      "tensor(7973, device='cuda:0') pects\n",
      "tensor(678, device='cuda:0')  all\n",
      "tensor(18034, device='cuda:0')  exclus\n",
      "tensor(908, device='cuda:0') ions\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(18611, device='cuda:0')   \n",
      "\n",
      "\n",
      "tensor(32, device='cuda:0') A\n",
      "tensor(3746, device='cuda:0')  strong\n",
      "tensor(2999, device='cuda:0')  option\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(6005, device='cuda:0') cor\n",
      "tensor(278, device='cuda:0') al\n",
      "tensor(56533, device='cuda:0') ”:\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(272, device='cuda:0')  c\n",
      "tensor(297, device='cuda:0')  o\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(1365, device='cuda:0')  –\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(8356, device='cuda:0')  fixed\n",
      "tensor(518, device='cuda:0')  at\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(19, device='cuda:0') 4\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(18536, device='cuda:0') good\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(1365, device='cuda:0')  –\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(5780, device='cuda:0')  goes\n",
      "tensor(311, device='cuda:0')  to\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(20967, device='cuda:0') allowed\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(537, device='cuda:0')  not\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(1365, device='cuda:0')  –\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(5780, device='cuda:0')  goes\n",
      "tensor(311, device='cuda:0')  to\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(20967, device='cuda:0') allowed\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(537, device='cuda:0')  not\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(14, device='cuda:0') /\n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(1365, device='cuda:0')  –\n",
      "tensor(38919, device='cuda:0')  introduces\n",
      "tensor(1378, device='cuda:0')  two\n",
      "tensor(7722, device='cuda:0')  fresh\n",
      "tensor(11931, device='cuda:0')  letters\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(272, device='cuda:0')  c\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(297, device='cuda:0')  o\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(1393, device='cuda:0')  while\n",
      "tensor(7497, device='cuda:0')  testing\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(1602, device='cuda:0')  very\n",
      "tensor(20757, device='cuda:0')  frequent\n",
      "tensor(76181, device='cuda:0')  vowel\n",
      "tensor(297, device='cuda:0')  o\n",
      "tensor(382, device='cuda:0') .\n",
      "\n",
      "\n",
      "tensor(2679, device='cuda:0') If\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(6005, device='cuda:0') cor\n",
      "tensor(278, device='cuda:0') al\n",
      "tensor(854, device='cuda:0') ”\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(4969, device='cuda:0')  wrong\n",
      "tensor(432, device='cuda:0')  it\n",
      "tensor(686, device='cuda:0')  will\n",
      "tensor(2058, device='cuda:0')  still\n",
      "tensor(2968, device='cuda:0')  give\n",
      "tensor(11260, device='cuda:0')  plenty\n",
      "tensor(315, device='cuda:0')  of\n",
      "tensor(1995, device='cuda:0')  information\n",
      "tensor(911, device='cuda:0')  about\n",
      "tensor(1380, device='cuda:0')  where\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(9173, device='cuda:0')  belong\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(911, device='cuda:0')  about\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(9362, device='cuda:0')  presence\n",
      "tensor(315, device='cuda:0')  of\n",
      "tensor(297, device='cuda:0')  o\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(272, device='cuda:0')  c\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(1084, device='cuda:0')  It\n",
      "tensor(67901, device='cuda:0')  satisfies\n",
      "tensor(1449, device='cuda:0')  every\n",
      "tensor(3881, device='cuda:0')  known\n",
      "tensor(21568, device='cuda:0')  constraint\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(773, device='cuda:0')  so\n",
      "tensor(432, device='cuda:0')  it\n",
      "tensor(748, device='cuda:0') ’s\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(6437, device='cuda:0')  solid\n",
      "tensor(4843, device='cuda:0')  third\n",
      "tensor(21015, device='cuda:0') -round\n",
      "tensor(21730, device='cuda:0')  probe\n",
      "tensor(3918, device='cuda:0') .</\n",
      "tensor(26865, device='cuda:0') think\n",
      "tensor(1784, device='cuda:0') ><\n",
      "tensor(9217, device='cuda:0') answer\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(6005, device='cuda:0') cor\n",
      "tensor(278, device='cuda:0') al\n",
      "tensor(522, device='cuda:0') </\n",
      "tensor(9217, device='cuda:0') answer\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(151645, device='cuda:0') <|im_end|>\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "tensor(13708, device='cuda:0') <th\n",
      "tensor(766, device='cuda:0') ink\n",
      "tensor(397, device='cuda:0') >\n",
      "\n",
      "tensor(3830, device='cuda:0') From\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(6005, device='cuda:0') cor\n",
      "tensor(278, device='cuda:0') al\n",
      "tensor(854, device='cuda:0') ”\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(425, device='cuda:0')  B\n",
      "tensor(479, device='cuda:0')  G\n",
      "tensor(809, device='cuda:0')  Y\n",
      "tensor(479, device='cuda:0')  G\n",
      "tensor(479, device='cuda:0')  G\n",
      "tensor(582, device='cuda:0')  we\n",
      "tensor(614, device='cuda:0')  have\n",
      "tensor(510, device='cuda:0') :\n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(272, device='cuda:0')  c\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(966, device='cuda:0') pos\n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(425, device='cuda:0')  B\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(272, device='cuda:0')  c\n",
      "tensor(27211, device='cuda:0')  absent\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(297, device='cuda:0')  o\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(966, device='cuda:0') pos\n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(479, device='cuda:0')  G\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(297, device='cuda:0')  o\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(8356, device='cuda:0')  fixed\n",
      "tensor(518, device='cuda:0')  at\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(966, device='cuda:0') pos\n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(809, device='cuda:0')  Y\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(714, device='cuda:0')  but\n",
      "tensor(537, device='cuda:0')  not\n",
      "tensor(518, device='cuda:0')  at\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(966, device='cuda:0') pos\n",
      "tensor(19, device='cuda:0') 4\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(479, device='cuda:0')  G\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(8356, device='cuda:0')  fixed\n",
      "tensor(518, device='cuda:0')  at\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(19, device='cuda:0') 4\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(966, device='cuda:0') pos\n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(479, device='cuda:0')  G\n",
      "tensor(11397, device='cuda:0')  →\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(8356, device='cuda:0')  fixed\n",
      "tensor(518, device='cuda:0')  at\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(18611, device='cuda:0')   \n",
      "\n",
      "\n",
      "tensor(33041, device='cuda:0') Earlier\n",
      "tensor(42675, device='cuda:0')  clues\n",
      "tensor(2058, device='cuda:0')  still\n",
      "tensor(3796, device='cuda:0')  apply\n",
      "tensor(25, device='cuda:0') :\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(4142, device='cuda:0') –\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(572, device='cuda:0')  was\n",
      "tensor(809, device='cuda:0')  Y\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(315, device='cuda:0')  of\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(75, device='cuda:0') l\n",
      "tensor(84992, device='cuda:0') unar\n",
      "tensor(9336, device='cuda:0') ”,\n",
      "tensor(773, device='cuda:0')  so\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(1410, device='cuda:0')  could\n",
      "tensor(537, device='cuda:0')  not\n",
      "tensor(387, device='cuda:0')  be\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(476, device='cuda:0')  or\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(17, device='cuda:0') 2\n",
      "tensor(26, device='cuda:0') ;\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(1431, device='cuda:0')  now\n",
      "tensor(10774, device='cuda:0')  confirmed\n",
      "tensor(6176, device='cuda:0')  green\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(12966, device='cuda:0')  consistent\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(4142, device='cuda:0') –\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(572, device='cuda:0')  was\n",
      "tensor(809, device='cuda:0')  Y\n",
      "tensor(304, device='cuda:0')  in\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(315, device='cuda:0')  of\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(75, device='cuda:0') l\n",
      "tensor(84992, device='cuda:0') unar\n",
      "tensor(9336, device='cuda:0') ”,\n",
      "tensor(773, device='cuda:0')  so\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(4157, device='cuda:0')  cannot\n",
      "tensor(387, device='cuda:0')  be\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(20, device='cuda:0') 5\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(4695, device='cuda:0')  Now\n",
      "tensor(582, device='cuda:0')  we\n",
      "tensor(1083, device='cuda:0')  also\n",
      "tensor(1414, device='cuda:0')  know\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(4157, device='cuda:0')  cannot\n",
      "tensor(387, device='cuda:0')  be\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(54815, device='cuda:0') Therefore\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(1172, device='cuda:0')  only\n",
      "tensor(9664, device='cuda:0')  remaining\n",
      "tensor(1787, device='cuda:0')  open\n",
      "tensor(9446, device='cuda:0')  slot\n",
      "tensor(369, device='cuda:0')  for\n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(16, device='cuda:0') 1\n",
      "tensor(382, device='cuda:0') .\n",
      "\n",
      "\n",
      "tensor(5405, device='cuda:0') Current\n",
      "tensor(5383, device='cuda:0')  pattern\n",
      "tensor(25, device='cuda:0') :\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(435, device='cuda:0')  r\n",
      "tensor(297, device='cuda:0')  o\n",
      "tensor(716, device='cuda:0')  _\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(198, device='cuda:0') \n",
      "\n",
      "tensor(54745, device='cuda:0') Remaining\n",
      "tensor(9788, device='cuda:0')  unknown\n",
      "tensor(6524, device='cuda:0')  letter\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(2309, device='cuda:0')  position\n",
      "tensor(220, device='cuda:0')  \n",
      "tensor(18, device='cuda:0') 3\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(840, device='cuda:0') Ex\n",
      "tensor(10181, device='cuda:0') cluded\n",
      "tensor(11931, device='cuda:0')  letters\n",
      "tensor(773, device='cuda:0')  so\n",
      "tensor(3041, device='cuda:0')  far\n",
      "tensor(25, device='cuda:0') :\n",
      "tensor(274, device='cuda:0')  s\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(259, device='cuda:0')  t\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(384, device='cuda:0')  e\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(575, device='cuda:0')  u\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(308, device='cuda:0')  n\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(272, device='cuda:0')  c\n",
      "tensor(13, device='cuda:0') .\n",
      "tensor(2303, device='cuda:0')   \n",
      "\n",
      "tensor(35382, device='cuda:0') Allowed\n",
      "tensor(20006, device='cuda:0')  unused\n",
      "tensor(11931, device='cuda:0')  letters\n",
      "tensor(2924, device='cuda:0')  include\n",
      "tensor(379, device='cuda:0')  y\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(281, device='cuda:0')  p\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(294, device='cuda:0')  d\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(342, device='cuda:0')  g\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(305, device='cuda:0')  h\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(296, device='cuda:0')  m\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(600, device='cuda:0')  i\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(293, device='cuda:0')  b\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(282, device='cuda:0')  f\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(595, device='cuda:0')  k\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(2804, device='cuda:0')  q\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(348, device='cuda:0')  v\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(289, device='cuda:0')  w\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(856, device='cuda:0')  x\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(1147, device='cuda:0')  z\n",
      "tensor(382, device='cuda:0') .\n",
      "\n",
      "\n",
      "tensor(22464, device='cuda:0') Looking\n",
      "tensor(369, device='cuda:0')  for\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(4185, device='cuda:0')  common\n",
      "tensor(6364, device='cuda:0')  English\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(315, device='cuda:0')  of\n",
      "tensor(1352, device='cuda:0')  form\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(299, device='cuda:0') ro\n",
      "tensor(937, device='cuda:0')  ?\n",
      "tensor(452, device='cuda:0')  al\n",
      "tensor(854, device='cuda:0') ”\n",
      "tensor(448, device='cuda:0')  with\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(18034, device='cuda:0')  exclus\n",
      "tensor(908, device='cuda:0') ions\n",
      "tensor(510, device='cuda:0') :\n",
      "\n",
      "tensor(6667, device='cuda:0') •\n",
      "tensor(29236, device='cuda:0')  royal\n",
      "tensor(320, device='cuda:0')  (\n",
      "tensor(81, device='cuda:0') r\n",
      "tensor(297, device='cuda:0')  o\n",
      "tensor(379, device='cuda:0')  y\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(326, device='cuda:0')  l\n",
      "tensor(8, device='cuda:0') )\n",
      "tensor(18304, device='cuda:0')  fits\n",
      "tensor(13942, device='cuda:0')  perfectly\n",
      "tensor(2293, device='cuda:0') —\n",
      "tensor(4776, device='cuda:0') uses\n",
      "tensor(264, device='cuda:0')  a\n",
      "tensor(501, device='cuda:0')  new\n",
      "tensor(6524, device='cuda:0')  letter\n",
      "tensor(379, device='cuda:0')  y\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(97402, device='cuda:0')  obe\n",
      "tensor(1047, device='cuda:0') ys\n",
      "tensor(678, device='cuda:0')  all\n",
      "tensor(16982, device='cuda:0')  constraints\n",
      "tensor(11, device='cuda:0') ,\n",
      "tensor(323, device='cuda:0')  and\n",
      "tensor(5868, device='cuda:0')  looks\n",
      "tensor(1075, device='cuda:0')  like\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(1172, device='cuda:0')  only\n",
      "tensor(19119, device='cuda:0')  ordinary\n",
      "tensor(6364, device='cuda:0')  English\n",
      "tensor(3409, device='cuda:0')  word\n",
      "tensor(429, device='cuda:0')  that\n",
      "tensor(9071, device='cuda:0')  matches\n",
      "tensor(382, device='cuda:0') .\n",
      "\n",
      "\n",
      "tensor(44500, device='cuda:0') Thus\n",
      "tensor(1036, device='cuda:0')  “\n",
      "tensor(3352, device='cuda:0') roy\n",
      "tensor(278, device='cuda:0') al\n",
      "tensor(854, device='cuda:0') ”\n",
      "tensor(374, device='cuda:0')  is\n",
      "tensor(279, device='cuda:0')  the\n",
      "tensor(19819, device='cuda:0')  logical\n",
      "tensor(1790, device='cuda:0')  next\n",
      "tensor(7942, device='cuda:0')  guess\n",
      "tensor(3918, device='cuda:0') .</\n",
      "tensor(26865, device='cuda:0') think\n",
      "tensor(1784, device='cuda:0') ><\n",
      "tensor(9217, device='cuda:0') answer\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(3352, device='cuda:0') roy\n",
      "tensor(278, device='cuda:0') al\n",
      "tensor(522, device='cuda:0') </\n",
      "tensor(9217, device='cuda:0') answer\n",
      "tensor(29, device='cuda:0') >\n",
      "tensor(151645, device='cuda:0') <|im_end|>\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n",
      "MASKED\n"
     ]
    }
   ],
   "source": [
    "non_masked_labels = []\n",
    "for label in processed['labels']:\n",
    "    if label != -100:    \n",
    "        print(label, tokenizer.decode(label))\n",
    "    else:\n",
    "        print('MASKED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are a Wordle solver assistant. Your goal is to correctly guess the hidden 5-letter word within six attempts. The game provides feedback after each guess, which you must use to refine your subsequent guesses. Follow these rules and strategies carefully:\\n\\n== Wordle Rules ==\\n1. The target word is exactly 5 letters long and is a valid English word.\\n2. After each guess, you will receive feedback consisting of a string of 5 characters using the letters:\\n   - G (Green): Correct letter in the correct position.\\n   - Y (Yellow): Correct letter in the wrong position.\\n   - B (Black): Letter is not in the target word at all.\\n3. Use the feedback to eliminate invalid words and improve future guesses.\\n\\n== Feedback Interpretation Examples ==\\n- Target word: \"hello\"\\n- Guess: \"world\"\\n- Feedback: \"BYBGB\"\\n  Explanation:\\n    - \"w\" → B: not in the target word\\n    - \"o\" → Y: in the word, but not in position 2\\n    - \"r\" → B: not in the word\\n    - \"l\" → G: correct letter and position (index 3)\\n    - \"d\" → B: not in the word\\n\\n== Your Responsibilities ==\\n- Generate a single valid 5-letter English word for each turn.\\n- Use previous guesses and their feedback to eliminate impossible candidates.\\n- Prioritize guesses that test multiple hypotheses (e.g., new letters or positions) when unsure.\\n- Think step-by-step to explain your reasoning before producing each guess.\\n\\n== Output Format ==\\nYour response must follow this structure:\\n<think>Explain your reasoning and deduction based on prior guesses and feedback.</think><answer>guess</answer>\\n\\n- The text inside <think> and </think> should include your full reasoning step by step. Do not ignore this step.\\n- The word inside <answer> and </answer> must be your final guess.\\n- The guess must be a single valid 5-letter English word in lowercase only.\\n- Do not include any other text outside of the <think> and <answer> tags.\\n\\n== Goal ==\\nCorrectly identify the hidden word using logical deduction and strategic guessing, with clear and structured reasoning output.',\n",
       "  'role': 'system'},\n",
       " {'content': 'Your first guess is?', 'role': 'user'},\n",
       " {'content': '<think>For the opening move, I want a word containing several of the most common consonants (s, t, l) and vowels (a, e) to maximize information. “slate” is a well-balanced starter that tests five high-frequency letters and provides good coverage for both vowels and consonants.</think><answer>slate</answer>',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'slate -> BYYBB', 'role': 'user'},\n",
       " {'content': '<think>Feedback “BYYBB” from “slate” means:\\n• s (pos1) – B → s is not in the word.  \\n• l (pos2) – Y → l is in the word but NOT in position 2.  \\n• a (pos3) – Y → a is in the word but NOT in position 3.  \\n• t (pos4) – B → t is not in the word.  \\n• e (pos5) – B → e is not in the word.  \\n\\nCurrent constraints  \\n– Contains: l (≠ pos2), a (≠ pos3)  \\n– Excludes: s, t, e  \\n– Positions 4 and 5 completely open; positions 1 and 3 cannot be l and a respectively, but could hold other letters.  \\n– Still need to learn about other common letters (o, u, i, n, r, d, c, h, p, etc.).\\n\\nI want a word that:  \\n1. Places l and a in allowable positions, satisfying their Y clues,  \\n2. Introduces three new high-value letters to maximise information, and  \\n3. Avoids the banned letters s, t, e.\\n\\n“lunar” fits:  \\n– l in position 1 (allowed)  \\n– u n r are fresh letters to test  \\n– a in position 4 (allowed, not position 3)  \\n– No s/t/e.\\n\\nThis guess advances knowledge on two more vowels (u) and several frequent consonants (n, r) while honoring all constraints.</think><answer>lunar</answer>',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'lunar -> YBBGY', 'role': 'user'},\n",
       " {'content': '<think>From the two guesses so far we have these firm constraints:\\n\\n• a is Green in position 4  → pattern _ _ _ a _  \\n• l is in the word but NOT in positions 1 or 2  \\n• r is in the word but NOT in position 5  \\n• Letters that are definitely absent: s, t, e, u, n  \\n  (from “slate” and “lunar”)  \\n\\nOpen slots: positions 1, 2, 3, 5.  \\nWe still need at least the letters l and r placed somewhere among those slots, with l ≠1,2 and r ≠5.  \\n\\nI’d like a candidate that  \\n1. Puts l and r in legal positions,  \\n2. Tries a high-value new vowel (o) and another common consonant,  \\n3. Respects all exclusions.  \\n\\nA strong option is “coral”:  \\n• c o r a l  \\n  – a is fixed at position 4 (good)  \\n  – r goes to position 3 (allowed, not 5)  \\n  – l goes to position 5 (allowed, not 1/2)  \\n  – introduces two fresh letters, c and o, while testing the very frequent vowel o.\\n\\nIf “coral” is wrong it will still give plenty of information about where r and l belong and about the presence of o and c. It satisfies every known constraint, so it’s a solid third-round probe.</think><answer>coral</answer>',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'coral -> BGYGG', 'role': 'user'},\n",
       " {'content': '<think>\\nFrom “coral” → B G Y G G we have:\\n• c (pos1) B → c absent.  \\n• o (pos2) G → o is fixed at position 2.  \\n• r (pos3) Y → r is in the word but not at position 3.  \\n• a (pos4) G → a is fixed at position 4.  \\n• l (pos5) G → l is fixed at position 5.  \\n\\nEarlier clues still apply:  \\n– l was Y in position 1 of “lunar”, so l could not be position 1 or 2; position 5 is now confirmed green, consistent.  \\n– r was Y in position 5 of “lunar”, so r cannot be position 5. Now we also know r cannot be position 3.  \\nTherefore the only remaining open slot for r is position 1.\\n\\nCurrent pattern:  r o _ a l\\nRemaining unknown letter is position 3.  \\nExcluded letters so far: s, t, e, u, n, c.  \\nAllowed unused letters include y, p, d, g, h, m, i, b, f, k, q, v, w, x, z.\\n\\nLooking for a common English word of form “ro ? al” with the exclusions:\\n• royal (r o y a l) fits perfectly—uses a new letter y, obeys all constraints, and looks like the only ordinary English word that matches.\\n\\nThus “royal” is the logical next guess.</think><answer>royal</answer>',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Success! You found the word royal in 4 turns.', 'role': 'user'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset[0]['messages'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "content = json.load(open('/home/ubuntu/Wordle/English Words Dictionary.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(content.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "<|im_start|>user\n",
      "What is the capital of France?<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/ubuntu/TauBench/tau-bench/Model Tuning/Qwen2.5-7B-Instruct\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\"/home/ubuntu/TauBench/tau-bench/Model Tuning/Qwen2.5-7B-Instruct\")\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"}\n",
    "]\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize = False,add_generation_prompt=False)\n",
    "print(prompt)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\nYou are a helpful assistant.<|im_end|>\\n<|im_start|>user\\nWhat is the capital of France?<|im_end|>\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-29 15:18:18 [config.py:823] This model supports multiple tasks: {'generate', 'classify', 'score', 'embed', 'reward'}. Defaulting to 'generate'.\n",
      "INFO 06-29 15:18:18 [config.py:2195] Chunked prefill is enabled with max_num_batched_tokens=4096.\n",
      "INFO 06-29 15:18:20 [core.py:455] Waiting for init message from front-end.\n",
      "INFO 06-29 15:18:20 [core.py:70] Initializing a V1 LLM engine (v0.9.1) with config: model='/home/ubuntu/TauBench/tau-bench/Model Tuning/Qwen2.5-0.5B', speculative_config=None, tokenizer='/home/ubuntu/TauBench/tau-bench/Model Tuning/Qwen2.5-0.5B', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config={}, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=4092, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=1337, served_model_name=/home/ubuntu/TauBench/tau-bench/Model Tuning/Qwen2.5-0.5B, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[\"none\"],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "WARNING 06-29 15:18:20 [utils.py:2737] Methods determine_num_available_blocks,device_config,get_cache_block_size_bytes,initialize_cache not implemented in <vllm.v1.worker.gpu_worker.Worker object at 0x78252c30b740>\n",
      "INFO 06-29 15:18:21 [parallel_state.py:1065] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "WARNING 06-29 15:18:21 [topk_topp_sampler.py:59] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "INFO 06-29 15:18:21 [gpu_model_runner.py:1595] Starting to load model /home/ubuntu/TauBench/tau-bench/Model Tuning/Qwen2.5-0.5B...\n",
      "INFO 06-29 15:18:21 [gpu_model_runner.py:1600] Loading model from scratch...\n",
      "INFO 06-29 15:18:21 [cuda.py:252] Using Flash Attention backend on V1 engine.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac4e9301c9347cca190e829bfb3ba44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 06-29 15:18:22 [default_loader.py:272] Loading weights took 0.24 seconds\n",
      "INFO 06-29 15:18:22 [gpu_model_runner.py:1624] Model loading took 0.9264 GiB and 0.447787 seconds\n",
      "INFO 06-29 15:18:29 [backends.py:462] Using cache directory: /home/ubuntu/.cache/vllm/torch_compile_cache/63e485f994/rank_0_0 for vLLM's torch.compile\n",
      "INFO 06-29 15:18:29 [backends.py:472] Dynamo bytecode transform time: 6.71 s\n",
      "INFO 06-29 15:18:33 [backends.py:161] Cache the graph of shape None for later use\n",
      "INFO 06-29 15:18:51 [backends.py:173] Compiling a graph for general shape takes 21.61 s\n",
      "INFO 06-29 15:18:57 [monitor.py:34] torch.compile takes 28.32 s in total\n",
      "INFO 06-29 15:18:59 [gpu_worker.py:227] Available KV cache memory: 5.52 GiB\n",
      "INFO 06-29 15:18:59 [kv_cache_utils.py:715] GPU KV cache size: 482,304 tokens\n",
      "INFO 06-29 15:18:59 [kv_cache_utils.py:719] Maximum concurrency for 4,092 tokens per request: 117.75x\n",
      "INFO 06-29 15:19:24 [gpu_model_runner.py:2048] Graph capturing finished in 25 secs, took 0.38 GiB\n",
      "INFO 06-29 15:19:24 [core.py:171] init engine (profile, create kv cache, warmup model) took 62.05 seconds\n"
     ]
    }
   ],
   "source": [
    "from vllm import LLM\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = '/home/ubuntu/TauBench/tau-bench/Model Tuning/Qwen2.5-0.5B'\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = LLM(\n",
    "                    model=model.name_or_path,\n",
    "                    tensor_parallel_size=1,\n",
    "                    gpu_memory_utilization=0.3,\n",
    "                    max_num_seqs=2,\n",
    "                    max_model_len=4092,\n",
    "                    # distributed_executor_backend=\"external_launcher\",\n",
    "                    # Feed identical seed for tp groups to ensure sampling results are the same across workers\n",
    "                    seed=1337,\n",
    "                    # Latest vLLM v1 memory profiler is misled by the high default value (i.e., 32768) - thinking there's not enough memory\n",
    "                    max_num_batched_tokens=4096,\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efef3057a584411eaf71037e5fea6ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding requests:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "inputs must be a string, TextPrompt, TokensPrompt, or EmbedsPrompt",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      1\u001b[39m messages =[\n\u001b[32m      2\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mYou are a helpful assistant.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m      3\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWhat is the capital of France?\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m      4\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/vllm/utils.py:1267\u001b[39m, in \u001b[36mdeprecate_kwargs.<locals>.wrapper.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m   1260\u001b[39m             msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madditional_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m   1262\u001b[39m         warnings.warn(\n\u001b[32m   1263\u001b[39m             \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m(msg),\n\u001b[32m   1264\u001b[39m             stacklevel=\u001b[32m3\u001b[39m,  \u001b[38;5;66;03m# The inner function takes up one level\u001b[39;00m\n\u001b[32m   1265\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1267\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/vllm/entrypoints/llm.py:464\u001b[39m, in \u001b[36mLLM.generate\u001b[39m\u001b[34m(self, prompts, sampling_params, prompt_token_ids, use_tqdm, lora_request, prompt_adapter_request, guided_options_request, priority)\u001b[39m\n\u001b[32m    460\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sampling_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    461\u001b[39m     \u001b[38;5;66;03m# Use default sampling params.\u001b[39;00m\n\u001b[32m    462\u001b[39m     sampling_params = \u001b[38;5;28mself\u001b[39m.get_default_sampling_params()\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_and_add_requests\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_prompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m    \u001b[49m\u001b[43mguided_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mguided_options_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m outputs = \u001b[38;5;28mself\u001b[39m._run_engine(use_tqdm=use_tqdm)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine_class.validate_outputs(outputs, RequestOutput)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/vllm/entrypoints/llm.py:1442\u001b[39m, in \u001b[36mLLM._validate_and_add_requests\u001b[39m\u001b[34m(self, prompts, params, use_tqdm, lora_request, prompt_adapter_request, tokenization_kwargs, guided_options, priority)\u001b[39m\n\u001b[32m   1439\u001b[39m     it = tqdm_func(it, desc=\u001b[33m\"\u001b[39m\u001b[33mAdding requests\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1441\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, prompt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(it):\n\u001b[32m-> \u001b[39m\u001b[32m1442\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_add_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1443\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1444\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1445\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1446\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   1447\u001b[39m \u001b[43m            \u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1448\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1449\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1450\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/vllm/entrypoints/llm.py:1462\u001b[39m, in \u001b[36mLLM._add_request\u001b[39m\u001b[34m(self, prompt, params, tokenization_kwargs, lora_request, prompt_adapter_request, priority)\u001b[39m\n\u001b[32m   1452\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_add_request\u001b[39m(\n\u001b[32m   1453\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1454\u001b[39m     prompt: PromptType,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1459\u001b[39m     priority: \u001b[38;5;28mint\u001b[39m = \u001b[32m0\u001b[39m,\n\u001b[32m   1460\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1461\u001b[39m     request_id = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m.request_counter))\n\u001b[32m-> \u001b[39m\u001b[32m1462\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mllm_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43madd_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1464\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/vllm/v1/engine/llm_engine.py:196\u001b[39m, in \u001b[36mLLMEngine.add_request\u001b[39m\u001b[34m(self, request_id, prompt, params, arrival_time, lora_request, tokenization_kwargs, trace_headers, prompt_adapter_request, priority)\u001b[39m\n\u001b[32m    183\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_request\u001b[39m(\n\u001b[32m    184\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    185\u001b[39m     request_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    194\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    195\u001b[39m     \u001b[38;5;66;03m# Process raw inputs into the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     prompt_str, request = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprocess_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marrival_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrace_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpriority\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     n = params.n \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(params, SamplingParams) \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m\n\u001b[32m    203\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n == \u001b[32m1\u001b[39m:\n\u001b[32m    204\u001b[39m         \u001b[38;5;66;03m# Make a new RequestState and queue.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/vllm/v1/engine/processor.py:243\u001b[39m, in \u001b[36mProcessor.process_inputs\u001b[39m\u001b[34m(self, request_id, prompt, params, arrival_time, lora_request, tokenization_kwargs, trace_headers, prompt_adapter_request, priority, data_parallel_rank)\u001b[39m\n\u001b[32m    236\u001b[39m     arrival_time = time.time()\n\u001b[32m    238\u001b[39m \u001b[38;5;66;03m# Process inputs, which includes:\u001b[39;00m\n\u001b[32m    239\u001b[39m \u001b[38;5;66;03m# 1. Tokenize text prompt, with LoRA request if one exists.\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[38;5;66;03m# 2. For multimodal models with a merged preprocessor, preprocess\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[38;5;66;03m#   multimodal data and expand prompt token ids accordingly.\u001b[39;00m\n\u001b[32m    242\u001b[39m \u001b[38;5;66;03m# 3. Apply prompt adapter to prompt token ids if one exists.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m processed_inputs: ProcessorInputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minput_preprocessor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    245\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_mm_hashes\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43muse_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mvllm\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mplatforms\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m current_platform\n\u001b[32m    251\u001b[39m current_platform.validate_request(\n\u001b[32m    252\u001b[39m     prompt=prompt,\n\u001b[32m    253\u001b[39m     params=params,\n\u001b[32m    254\u001b[39m     processed_inputs=processed_inputs,\n\u001b[32m    255\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/vllm/inputs/preprocess.py:870\u001b[39m, in \u001b[36mInputPreprocessor.preprocess\u001b[39m\u001b[34m(self, prompt, tokenization_kwargs, lora_request, prompt_adapter_request, return_mm_hashes)\u001b[39m\n\u001b[32m    866\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot pass encoder-decoder prompt \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    867\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33mto decoder-only models\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    869\u001b[39m \u001b[38;5;66;03m# Decoder-only operation\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m870\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_decoder_only_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_adapter_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_mm_hashes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_mm_hashes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/vllm/inputs/preprocess.py:812\u001b[39m, in \u001b[36mInputPreprocessor._process_decoder_only_prompt\u001b[39m\u001b[34m(self, prompt, tokenization_kwargs, lora_request, prompt_adapter_request, return_mm_hashes)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_process_decoder_only_prompt\u001b[39m(\n\u001b[32m    788\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    789\u001b[39m     prompt: SingletonPrompt,\n\u001b[32m   (...)\u001b[39m\u001b[32m    793\u001b[39m     return_mm_hashes: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    794\u001b[39m ) -> DecoderOnlyInputs:\n\u001b[32m    795\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    796\u001b[39m \u001b[33;03m    For decoder-only models:\u001b[39;00m\n\u001b[32m    797\u001b[39m \u001b[33;03m    Process an input prompt into a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    809\u001b[39m \u001b[33;03m    * [`DecoderOnlyInputs`][vllm.inputs.data.DecoderOnlyInputs] instance\u001b[39;00m\n\u001b[32m    810\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m812\u001b[39m     prompt_comps = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prompt_to_llm_inputs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    813\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    814\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenization_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    815\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlora_request\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    816\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_mm_hashes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_mm_hashes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    817\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._build_decoder_only_llm_inputs(\n\u001b[32m    820\u001b[39m         prompt_comps,\n\u001b[32m    821\u001b[39m         prompt_adapter_request=prompt_adapter_request,\n\u001b[32m    822\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/vllm/inputs/preprocess.py:484\u001b[39m, in \u001b[36mInputPreprocessor._prompt_to_llm_inputs\u001b[39m\u001b[34m(self, prompt, tokenization_kwargs, lora_request, return_mm_hashes)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_prompt_to_llm_inputs\u001b[39m(\n\u001b[32m    465\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    466\u001b[39m     prompt: SingletonPrompt,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m     return_mm_hashes: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    470\u001b[39m ) -> SingletonInputs:\n\u001b[32m    471\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    472\u001b[39m \u001b[33;03m    Extract the singleton inputs from a prompt.\u001b[39;00m\n\u001b[32m    473\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    482\u001b[39m \u001b[33;03m    * [`SingletonInputs`][vllm.inputs.data.SingletonInputs] instance\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m484\u001b[39m     parsed = \u001b[43mparse_singleton_prompt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parsed[\u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33membeds\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    487\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_embeds(parsed[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Wordle/.venv/lib/python3.12/site-packages/vllm/inputs/parse.py:132\u001b[39m, in \u001b[36mparse_singleton_prompt\u001b[39m\u001b[34m(prompt)\u001b[39m\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mprompt\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m prompt:\n\u001b[32m    131\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m ParsedTextPrompt(\u001b[38;5;28mtype\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mtext\u001b[39m\u001b[33m\"\u001b[39m, content=prompt)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    133\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33minputs must be a string, TextPrompt, TokensPrompt, or EmbedsPrompt\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: inputs must be a string, TextPrompt, TokensPrompt, or EmbedsPrompt"
     ]
    }
   ],
   "source": [
    "messages =[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm.generate(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
